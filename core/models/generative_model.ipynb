{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Data\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "# Function to load data from a FASTA file\n",
    "def load_fasta_file(file_path):\n",
    "    sequences = []\n",
    "    virus_types = []\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        sequences.append(str(record.seq))\n",
    "        virus_type = record.description.split()[\n",
    "            0\n",
    "        ]  # Assuming virus type is the first element\n",
    "        virus_types.append(virus_type)\n",
    "    return sequences, virus_types\n",
    "\n",
    "\n",
    "# Path to your FASTA file\n",
    "fasta_file_path = \"\"\n",
    "\n",
    "# Load data from the FASTA file\n",
    "sequences, virus_types = load_fasta_file(fasta_file_path)\n",
    "\n",
    "# Print the number of sequences and types\n",
    "num_sequences = len(sequences)\n",
    "print(\"Number of Sequences:\", num_sequences)\n",
    "\n",
    "# Check the first few sequences and their associated virus types\n",
    "for i in range(5):  # Adjust the range to see more sequences if needed\n",
    "    print(f\"Sequence {i+1}: {sequences[i]}\")\n",
    "    print(f\"Virus Type: {virus_types[i]}\")\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 Prepare Data For Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def prepare_data(sequences):\n",
    "    all_sequences = sequences\n",
    "\n",
    "    tokenizer = Tokenizer(char_level=True)\n",
    "    tokenizer.fit_on_texts(all_sequences)\n",
    "\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    input_sequences = []\n",
    "    for seq in all_sequences:\n",
    "        token_list = tokenizer.texts_to_sequences([seq])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[: i + 1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "    max_sequence_length = max([len(seq) for seq in input_sequences])\n",
    "    padded_sequences = pad_sequences(\n",
    "        input_sequences, maxlen=max_sequence_length, padding=\"pre\"\n",
    "    )\n",
    "\n",
    "    predictors, label = padded_sequences[:, :-1], padded_sequences[:, -1]\n",
    "\n",
    "    return predictors, label, total_words, max_sequence_length, tokenizer\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "predictors, label, total_words, max_sequence_length, tokenizer = prepare_data(sequences)\n",
    "\n",
    "# Check the prepared data\n",
    "print(predictors.shape)\n",
    "print(label.shape)\n",
    "print(total_words)\n",
    "print(max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 Making Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "\n",
    "def build_model(total_words, max_sequence_length):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Embedding(total_words, 50, input_length=max_sequence_length - 1)\n",
    "    )  # Remove input-length argument\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(total_words, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build the model\n",
    "model = build_model(total_words, max_sequence_length)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Train The Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Adjust epochs,verbose and patience according to your data\n",
    "def train_model(model, predictors, label):\n",
    "    model.fit(predictors, label, epochs=, verbose=, callbacks=[EarlyStopping(monitor='loss', patience=, restore_best_weights=True)])\n",
    "\n",
    "# Train the model\n",
    "train_model(model, predictors, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generating New Sequence Type\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def generate_sequence(model, tokenizer, max_sequence_length, seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences(\n",
    "            [token_list], maxlen=max_sequence_length - 1, padding=\"pre\"\n",
    "        )\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        # Choose the word with some randomness to introduce diversity\n",
    "        predicted_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "\n",
    "        seed_text += output_word.upper()\n",
    "\n",
    "    return seed_text\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    while True:\n",
    "        generate_sequence_input = input(\n",
    "            \"Do you want to generate a sequence? (yes/no): \"\n",
    "        ).lower()\n",
    "        if generate_sequence_input == \"yes\":\n",
    "            length_input = int(\n",
    "                input(\n",
    "                    \"Enter the length of the sequence to generate (between 100 and 15000): \"\n",
    "                )\n",
    "            )\n",
    "            if 100 <= length_input <= 15000:\n",
    "                num_sequences_input = int(\n",
    "                    input(\n",
    "                        \"Enter the number of sequences to generate (between 1 and 10): \"\n",
    "                    )\n",
    "                )\n",
    "                if 1 <= num_sequences_input <= 10:\n",
    "                    return True, length_input, num_sequences_input\n",
    "                else:\n",
    "                    print(\n",
    "                        \"Please enter a number between 1 and 10 for the number of sequences.\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\"Please enter a number between 100 and 15000.\")\n",
    "        elif generate_sequence_input == \"no\":\n",
    "            return False, 0, 0\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    generate, length, num_sequences = get_user_input()\n",
    "    if not generate:\n",
    "        break\n",
    "\n",
    "    seed_sequence = \"Type_5:\"  # You can change this to start with any type you want\n",
    "    for _ in range(num_sequences):\n",
    "        generated_sequence = generate_sequence(\n",
    "            model, tokenizer, max_sequence_length, seed_sequence, length\n",
    "        )\n",
    "\n",
    "        # Print the generated sequence\n",
    "        print(generated_sequence)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
